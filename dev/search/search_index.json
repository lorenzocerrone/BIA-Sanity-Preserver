{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udd2c BIA Sanity Preserver \ud83e\udde0","text":"<p>Because setting up bio image analysis tools shouldn\u2019t cost you your sanity.</p> <p>Setting up bio image analysis (BIA) tools the sane way is hard. Requirements change. Dependencies fight. Conflicts arise. Environments grow tangled and break.</p> <p>BIA Sanity Preserver is here to restore balance.</p> <p>With it, you can install and run your favourite bio image analysis tools in clean, isolated environments, avoiding conflicts and keeping your workflows reproducible and drama-free.</p>"},{"location":"#the-idea","title":"\ud83e\udde9 The Idea","text":"<p>In one work, use pixi. No containers, no complexity, just pure, isolated environments.</p> <p>\ud83d\udce6  Each tool gets its own dedicated environment. \u26a1 Environments can be quickly created, fearlessly modified (thanks to pixi locks \ud83d\udd12), and easily deleted.</p>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>All you need is:</p> <ol> <li>pixi installed \u2192 pixi</li> <li>This repository cloned:</li> </ol> <pre><code>git clone https://github.com/lorenzocerrone/BIA-Sanity-Preserver\n</code></pre> <p>That\u2019s it. You\u2019re officially on the path to BIA enlightenment.</p>"},{"location":"#tools-included","title":"\ud83d\udee0\ufe0f Tools Included","text":"<p>Run your tools with a single command and zero emotional damage:</p> <ul> <li>Cellpose</li> <li>Napari with OME-Zarr support</li> <li>ilastik</li> <li>Plant-seg</li> <li>Feature-explorer</li> </ul>"},{"location":"#environments","title":"\ud83c\udfd7\ufe0f Environments","text":"<p>Ready-to-use environments for bio image analysis:</p> <ul> <li>Python Scientific Stack</li> <li>Ngio</li> </ul>"},{"location":"#wish-list","title":"\ud83c\udf20 Wish List","text":"<ul> <li>StarDist</li> <li>...</li> </ul> <p>(Java-based tools are trickier to containerize with pixi, but it could be done!)</p> <ul> <li> <p>Fiji / ImageJ2   (PoC available: pixi-fiji)</p> </li> <li> <p>QuPath</p> </li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Any contributions are welcome! Here\u2019s how you can help:</p> <ul> <li>If something's not working, open an issue \ud83d\udc1b</li> <li>If you have ideas for new tools or improvements, open an issue \ud83d\udca1</li> <li>If you want to add a tool or improve an existing setup, submit a pull request \ud83d\ude80</li> </ul>"},{"location":"#testing","title":"\ud83e\uddea Testing","text":"<p>Each environment is automatically installed on Ubuntu, macOS, and Windows using GitHub Actions to ensure cross-platform compatibility. The tools themselves are not tested beyond installation.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Such a project can only thrive with the help of the community, to make sure that it stays up-to-date and useful for everyone. Here\u2019s how you can contribute:</p> <ul> <li>If you have ideas for new tools or improvements, open an issue \ud83d\udca1</li> <li>If you test some tools, and had an issue let us know by opening an issue \ud83d\udc1b</li> <li>If you know your way around pixi and want to add a tool or improve an existing setup, submit a pull request \ud83d\ude80</li> <li>If the documentation is lacking or unclear, feel free to suggest improvements via pull requests \u270d\ufe0f</li> </ul>"},{"location":"contributing/#testing","title":"\ud83e\uddea Testing","text":"<p>Each environment is automatically installed on Ubuntu, macOS, and Windows using GitHub Actions to ensure cross-platform compatibility. The tools themselves are not tested beyond installation.</p>"},{"location":"envs/ngio/","title":"ngio","text":"<p>ngio is a Python library designed for working with next-generation image formats, providing efficient access to modern image storage formats commonly used in bio image analysis.</p>"},{"location":"envs/ngio/#overview","title":"Overview","text":"<p>The ngio library provides a unified interface for reading and writing modern image formats, with a focus on performance, scalability, and interoperability with the broader scientific Python ecosystem.</p>"},{"location":"envs/ngio/#environment","title":"Environment","text":"<p>Environment: <code>ngio</code></p>"},{"location":"envs/ngio/#features","title":"Features","text":"<ul> <li>Modern format support: Native support for next-generation image formats</li> <li>Efficient I/O: Optimized reading and writing operations</li> <li>Chunked access: Efficient handling of large datasets through chunked access patterns</li> <li>Metadata preservation: Comprehensive metadata handling and preservation</li> <li>Lazy loading: Memory-efficient lazy loading of large image datasets</li> <li>Multi-dimensional support: Handle 2D, 3D, time-series, and multi-channel data</li> <li>Integration ready: Seamless integration with NumPy, Dask, and other scientific libraries</li> </ul>"},{"location":"envs/ngio/#supported-formats","title":"Supported Formats","text":""},{"location":"envs/ngio/#ome-zarr","title":"OME-Zarr","text":"<ul> <li>Specification compliant: Full support for OME-Zarr specification</li> <li>Multi-resolution: Handle multi-resolution image pyramids</li> <li>Cloud storage: Direct access to cloud-stored datasets</li> <li>Metadata: Rich metadata support including spatial and temporal information</li> </ul>"},{"location":"envs/ngio/#other-next-generation-formats","title":"Other Next-Generation Formats","text":"<ul> <li>Support for various modern image formats optimized for scientific applications</li> <li>Extensible architecture for adding new format support</li> <li>Integration with existing format libraries</li> </ul>"},{"location":"envs/ngio/#key-capabilities","title":"Key Capabilities","text":""},{"location":"envs/ngio/#efficient-data-access","title":"Efficient Data Access","text":"<pre><code>import ngio\n\n# Open large datasets efficiently\ndataset = ngio.open('large_dataset.ome.zarr')\n# Access specific regions without loading entire dataset\nregion = dataset[100:200, 150:250, :]\n</code></pre>"},{"location":"envs/ngio/#metadata-handling","title":"Metadata Handling","text":"<pre><code># Access comprehensive metadata\nmetadata = dataset.metadata\nspatial_info = metadata.spatial_calibration\nchannel_info = metadata.channels\n</code></pre>"},{"location":"envs/ngio/#integration-with-scientific-stack","title":"Integration with Scientific Stack","text":"<pre><code>import numpy as np\nimport dask.array as da\n\n# Convert to standard array types\nnumpy_array = np.array(dataset[:])\ndask_array = da.from_array(dataset)\n</code></pre>"},{"location":"envs/ngio/#use-cases","title":"Use Cases","text":""},{"location":"envs/ngio/#large-dataset-analysis","title":"Large Dataset Analysis","text":"<ul> <li>Efficiently work with multi-terabyte imaging datasets</li> <li>Stream data for analysis without memory constraints</li> <li>Process datasets that don't fit in memory</li> </ul>"},{"location":"envs/ngio/#cloud-based-workflows","title":"Cloud-Based Workflows","text":"<ul> <li>Access datasets stored in cloud storage directly</li> <li>Enable distributed analysis workflows</li> <li>Facilitate data sharing and collaboration</li> </ul>"},{"location":"envs/ngio/#format-conversion","title":"Format Conversion","text":"<ul> <li>Convert between different image formats</li> <li>Preserve metadata during conversion</li> <li>Batch processing of image collections</li> </ul>"},{"location":"envs/ngio/#integration-workflows","title":"Integration Workflows","text":"<ul> <li>Bridge between acquisition software and analysis pipelines</li> <li>Enable interoperability between different analysis tools</li> <li>Standardize data access patterns across workflows</li> </ul>"},{"location":"envs/ngio/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Activate the ngio environment for your analysis scripts</li> <li>Import ngio in your Python code and start working with modern image formats!</li> </ol>"},{"location":"envs/ngio/#performance-benefits","title":"Performance Benefits","text":"<ul> <li>Chunked storage: Efficient access patterns for large datasets</li> <li>Compression: Built-in compression reduces storage requirements</li> <li>Parallel access: Support for parallel reading operations</li> <li>Memory efficiency: Lazy loading prevents memory overflow</li> <li>Network optimization: Efficient access to remote datasets</li> </ul>"},{"location":"envs/ngio/#integration-examples","title":"Integration Examples","text":""},{"location":"envs/ngio/#with-napari","title":"With Napari","text":"<pre><code>import ngio\nimport napari\n\n# Open dataset with ngio and view in napari\ndataset = ngio.open('dataset.ome.zarr')\nviewer = napari.Viewer()\nviewer.add_image(dataset)\n</code></pre>"},{"location":"envs/ngio/#with-dask-for-parallel-processing","title":"With Dask for Parallel Processing","text":"<pre><code>import ngio\nimport dask.array as da\n\n# Use dask for parallel processing\ndataset = ngio.open('large_dataset.ome.zarr')\ndask_array = da.from_array(dataset, chunks=(512, 512, 10))\nprocessed = dask_array.map_blocks(your_processing_function)\nresult = processed.compute()\n</code></pre>"},{"location":"envs/ngio/#resources","title":"Resources","text":"<ul> <li>ngio documentation</li> <li>OME-Zarr specification</li> <li>Zarr documentation</li> </ul>"},{"location":"envs/python-scientific-stack/","title":"Python Scientific Stack","text":"<p>A comprehensive Python environment with all the essential libraries for bio image analysis, providing a solid foundation for scientific computing and image processing tasks.</p>"},{"location":"envs/python-scientific-stack/#overview","title":"Overview","text":"<p>The BIA-ready Python Scientific Stack includes carefully selected packages that form the backbone of most bio image analysis workflows, from basic image processing to advanced machine learning applications.</p>"},{"location":"envs/python-scientific-stack/#environment","title":"Environment","text":"<p>Environment: <code>bia-sci-py-stack</code></p>"},{"location":"envs/python-scientific-stack/#available-tasks","title":"Available Tasks","text":""},{"location":"envs/python-scientific-stack/#start-jupyterlab","title":"Start JupyterLab","text":"<p>Launch JupyterLab for interactive analysis:</p> <pre><code>pixi run jupyterlab\n</code></pre>"},{"location":"envs/python-scientific-stack/#included-libraries","title":"Included Libraries","text":""},{"location":"envs/python-scientific-stack/#core-scientific-computing","title":"Core Scientific Computing","text":"<ul> <li>numpy: Fundamental array computing library</li> <li>scipy: Scientific computing tools and algorithms</li> <li>pandas: Data manipulation and analysis library</li> <li>scikit-learn: Machine learning library with classification, regression, and clustering algorithms</li> </ul>"},{"location":"envs/python-scientific-stack/#image-processing","title":"Image Processing","text":"<ul> <li>scikit-image: Comprehensive image processing toolkit</li> <li>tifffile: Read and write TIFF files efficiently</li> <li>zarr: Chunked, compressed, N-dimensional arrays</li> </ul>"},{"location":"envs/python-scientific-stack/#visualization","title":"Visualization","text":"<ul> <li>matplotlib: Comprehensive plotting library</li> <li>seaborn: Statistical data visualization based on matplotlib</li> <li>plotly: Interactive plotting library</li> </ul>"},{"location":"envs/python-scientific-stack/#interactive-development","title":"Interactive Development","text":"<ul> <li>jupyterlab: Modern web-based interactive development environment</li> <li>ipywidgets: Interactive HTML widgets for Jupyter notebooks</li> </ul>"},{"location":"envs/python-scientific-stack/#parallel-computing","title":"Parallel Computing","text":"<ul> <li>dask: Parallel computing library for analytics</li> </ul>"},{"location":"envs/python-scientific-stack/#additional-tools","title":"Additional Tools","text":"<ul> <li>Various other specialized libraries for bio image analysis workflows</li> </ul>"},{"location":"envs/python-scientific-stack/#features","title":"Features","text":"<ul> <li>Complete environment: Everything needed for most bio image analysis tasks</li> <li>Optimized versions: Carefully selected compatible versions of all packages</li> <li>Ready to use: No additional setup required</li> <li>Extensible: Easy to add additional packages as needed</li> <li>Reproducible: Locked dependencies ensure consistent results</li> </ul>"},{"location":"envs/python-scientific-stack/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Run <code>pixi run jupyterlab</code> to start JupyterLab</li> <li>Create new notebooks or open existing ones to start your analysis!</li> </ol>"},{"location":"envs/python-scientific-stack/#common-use-cases","title":"Common Use Cases","text":""},{"location":"envs/python-scientific-stack/#image-processing_1","title":"Image Processing","text":"<pre><code>import numpy as np\nimport skimage\nfrom skimage import io, filters, segmentation\nimport matplotlib.pyplot as plt\n\n# Load and process images\nimage = io.imread('your_image.tif')\nfiltered = filters.gaussian(image, sigma=1.0)\nsegmented = segmentation.watershed(filtered)\n</code></pre>"},{"location":"envs/python-scientific-stack/#data-analysis","title":"Data Analysis","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Analyze measurement data\ndf = pd.read_csv('measurements.csv')\ncorrelation_matrix = df.corr()\nsns.heatmap(correlation_matrix, annot=True)\n</code></pre>"},{"location":"envs/python-scientific-stack/#machine-learning","title":"Machine Learning","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Train a classifier on your features\nX_train, X_test, y_train, y_test = train_test_split(features, labels)\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n</code></pre>"},{"location":"envs/python-scientific-stack/#large-dataset-handling","title":"Large Dataset Handling","text":"<pre><code>import dask.array as da\nimport zarr\n\n# Handle large arrays efficiently\nlarge_array = da.from_zarr('large_dataset.zarr')\nresult = large_array.sum(axis=0).compute()\n</code></pre>"},{"location":"envs/python-scientific-stack/#advantages","title":"Advantages","text":"<ul> <li>Batteries included: No need to hunt down compatible library versions</li> <li>Conflict-free: All packages tested to work together harmoniously</li> <li>Performance optimized: Libraries compiled with optimizations where applicable</li> <li>Documentation ready: All standard libraries with full documentation</li> <li>Community supported: All packages are widely used and well-maintained</li> </ul>"},{"location":"envs/python-scientific-stack/#resources","title":"Resources","text":"<ul> <li>NumPy documentation</li> <li>SciPy documentation</li> <li>scikit-image documentation</li> <li>Pandas documentation</li> <li>JupyterLab documentation</li> </ul>"},{"location":"tools/cellpose/","title":"Cellpose","text":"<p>Cellpose is a generalist algorithm for cellular segmentation that works well on diverse cell types and images without the need for model retraining or parameter adjustment.</p>"},{"location":"tools/cellpose/#overview","title":"Overview","text":"<p>The Cellpose environment provides tools for 2D and 3D cell segmentation using deep learning models trained on a diverse dataset of cell images.</p>"},{"location":"tools/cellpose/#environment","title":"Environment","text":"<p>Environment: <code>cellpose</code></p>"},{"location":"tools/cellpose/#available-tasks","title":"Available Tasks","text":""},{"location":"tools/cellpose/#cellpose-2d-gui","title":"Cellpose 2D GUI","text":"<p>Start the Cellpose graphical interface for 2D segmentation:</p> <pre><code>pixi run cellpose\n</code></pre>"},{"location":"tools/cellpose/#cellpose-3d-gui","title":"Cellpose 3D GUI","text":"<p>Start the Cellpose graphical interface for 3D segmentation:</p> <pre><code>pixi run cellpose-3D\n</code></pre>"},{"location":"tools/cellpose/#features","title":"Features","text":"<ul> <li>2D and 3D segmentation: Supports both 2D and 3D cell segmentation</li> <li>Pre-trained models: Includes several pre-trained models for different cell types</li> <li>Custom training: Ability to train custom models on your own data</li> <li>GPU acceleration: Supports GPU acceleration for faster processing</li> <li>User-friendly GUI: Easy-to-use graphical interface for interactive segmentation</li> </ul>"},{"location":"tools/cellpose/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Run one of the available tasks above to start Cellpose</li> <li>Load your images and start segmenting!</li> </ol>"},{"location":"tools/cellpose/#resources","title":"Resources","text":"<ul> <li>Cellpose official documentation</li> <li>Cellpose paper</li> </ul>"},{"location":"tools/feature-explorer/","title":"Feature Explorer","text":"<p>Feature Explorer is a Python dashboard application for exploring OME-Zarr images alongside tabular data, specifically designed to work with outputs from the Fractal Image Analysis platform.</p>"},{"location":"tools/feature-explorer/#overview","title":"Overview","text":"<p>Feature Explorer provides an interactive web-based interface for visualizing and analyzing multi-dimensional image datasets with associated quantitative measurements and metadata.</p>"},{"location":"tools/feature-explorer/#environment","title":"Environment","text":"<p>Environment: <code>feature-explorer</code></p>"},{"location":"tools/feature-explorer/#available-tasks","title":"Available Tasks","text":""},{"location":"tools/feature-explorer/#start-feature-explorer-dashboard","title":"Start Feature Explorer Dashboard","text":"<p>Launch the interactive Feature Explorer dashboard:</p> <pre><code>pixi run feature-explorer\n</code></pre>"},{"location":"tools/feature-explorer/#features","title":"Features","text":"<ul> <li>Interactive visualization: Web-based dashboard for image and data exploration</li> <li>OME-Zarr support: Native support for OME-Zarr image format</li> <li>Tabular data integration: Seamlessly combine images with measurement data</li> <li>Multi-dimensional navigation: Explore 2D, 3D, and time-series datasets</li> <li>Feature analysis: Visualize and analyze extracted quantitative features</li> <li>Fractal integration: Optimized for Fractal Image Analysis platform outputs</li> <li>Real-time filtering: Interactive filtering and selection of data points</li> <li>Export capabilities: Export visualizations and filtered datasets</li> </ul>"},{"location":"tools/feature-explorer/#supported-data-types","title":"Supported Data Types","text":""},{"location":"tools/feature-explorer/#image-data","title":"Image Data","text":"<ul> <li>OME-Zarr format: Multi-resolution, chunked image arrays</li> <li>Multi-channel images: Fluorescence microscopy with multiple markers</li> <li>Time-series data: Time-lapse imaging datasets</li> <li>3D volumes: Confocal and light-sheet microscopy data</li> </ul>"},{"location":"tools/feature-explorer/#tabular-data","title":"Tabular Data","text":"<ul> <li>Feature measurements: Quantitative measurements extracted from images</li> <li>Metadata: Experimental conditions and sample information</li> <li>Segmentation results: Object properties and classifications</li> <li>Statistical summaries: Aggregated measurements and statistics</li> </ul>"},{"location":"tools/feature-explorer/#dashboard-components","title":"Dashboard Components","text":""},{"location":"tools/feature-explorer/#image-viewer","title":"Image Viewer","text":"<ul> <li>Multi-dimensional image display with zoom and pan</li> <li>Channel selection and blending</li> <li>Overlay of segmentation masks and annotations</li> <li>Real-time image updates based on data selection</li> </ul>"},{"location":"tools/feature-explorer/#data-explorer","title":"Data Explorer","text":"<ul> <li>Interactive tables with sorting and filtering</li> <li>Statistical plots and histograms</li> <li>Correlation analysis and scatter plots</li> <li>Feature distribution visualization</li> </ul>"},{"location":"tools/feature-explorer/#analysis-tools","title":"Analysis Tools","text":"<ul> <li>Quality control metrics and visualizations</li> <li>Batch comparison tools</li> <li>Export functionality for further analysis</li> <li>Integration with downstream analysis pipelines</li> </ul>"},{"location":"tools/feature-explorer/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Run <code>pixi run feature-explorer</code> to start the dashboard</li> <li>Open your browser and navigate to the provided URL</li> <li>Load your OME-Zarr images and associated tabular data</li> <li>Start exploring your datasets interactively!</li> </ol>"},{"location":"tools/feature-explorer/#use-cases","title":"Use Cases","text":"<ul> <li>Quality control: Assess image quality and analysis results</li> <li>Data exploration: Discover patterns and relationships in large datasets</li> <li>Result validation: Validate automated analysis results</li> <li>Comparative analysis: Compare results across different experimental conditions</li> <li>Visualization: Create publication-ready figures and visualizations</li> <li>Data filtering: Select subsets of data for downstream analysis</li> </ul>"},{"location":"tools/feature-explorer/#integration-with-fractal","title":"Integration with Fractal","text":"<p>Feature Explorer is specifically designed to work with outputs from the Fractal Image Analysis platform, providing: - Direct loading of Fractal workflow outputs - Visualization of processing results at each workflow step - Quality assessment of automated analysis pipelines - Interactive exploration of large-scale analysis results</p>"},{"location":"tools/feature-explorer/#resources","title":"Resources","text":"<ul> <li>Feature Explorer documentation</li> <li>Fractal platform documentation</li> <li>OME-Zarr specification</li> </ul>"},{"location":"tools/ilastik/","title":"ilastik","text":"<p>ilastik is an interactive machine learning toolkit that enables users to classify pixels, segment images, track objects, and count cells without requiring machine learning expertise.</p>"},{"location":"tools/ilastik/#overview","title":"Overview","text":"<p>The ilastik environment provides a user-friendly interface for interactive machine learning-based image analysis, making advanced segmentation and classification accessible to biologists and researchers.</p>"},{"location":"tools/ilastik/#environment","title":"Environment","text":"<p>Environment: <code>ilastik</code></p>"},{"location":"tools/ilastik/#available-tasks","title":"Available Tasks","text":""},{"location":"tools/ilastik/#start-ilastik-gui","title":"Start ilastik GUI","text":"<p>Launch the ilastik graphical user interface:</p> <pre><code>pixi run ilastik\n</code></pre>"},{"location":"tools/ilastik/#features","title":"Features","text":"<ul> <li>Interactive machine learning: Train classifiers by providing examples</li> <li>Pixel classification: Classify pixels based on their local appearance</li> <li>Object classification: Classify segmented objects based on their features</li> <li>Carving workflow: Semi-automatic segmentation for challenging objects</li> <li>Tracking: Track objects across time-lapse sequences</li> <li>Counting: Automated object counting in images</li> <li>Batch processing: Process multiple images with trained classifiers</li> <li>Feature extraction: Comprehensive set of image features for analysis</li> </ul>"},{"location":"tools/ilastik/#workflows-available","title":"Workflows Available","text":""},{"location":"tools/ilastik/#pixel-classification","title":"Pixel Classification","text":"<p>Train a classifier to distinguish different tissue types, cell types, or structures at the pixel level.</p>"},{"location":"tools/ilastik/#object-classification","title":"Object Classification","text":"<p>Segment objects first, then classify them based on shape, intensity, and other features.</p>"},{"location":"tools/ilastik/#autocontext","title":"Autocontext","text":"<p>Improve classification results by using predictions as additional input features.</p>"},{"location":"tools/ilastik/#carving","title":"Carving","text":"<p>Interactive segmentation tool for separating touching or overlapping objects.</p>"},{"location":"tools/ilastik/#tracking","title":"Tracking","text":"<p>Track objects through time-lapse sequences with manual correction capabilities.</p>"},{"location":"tools/ilastik/#counting","title":"Counting","text":"<p>Count objects in images using density estimation or detection-based approaches.</p>"},{"location":"tools/ilastik/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Run <code>pixi run ilastik</code> to start the ilastik interface</li> <li>Choose your desired workflow and start training your classifier!</li> </ol>"},{"location":"tools/ilastik/#use-cases","title":"Use Cases","text":"<ul> <li>Cell segmentation: Separate cells from background and from each other</li> <li>Tissue classification: Classify different tissue types in histological images</li> <li>Organelle detection: Identify and classify cellular organelles</li> <li>Quality control: Classify images based on quality metrics</li> <li>Time-lapse analysis: Track cell division, migration, and other dynamic processes</li> </ul>"},{"location":"tools/ilastik/#resources","title":"Resources","text":"<ul> <li>ilastik documentation</li> <li>ilastik tutorials</li> <li>ilastik paper</li> </ul>"},{"location":"tools/napari-ome-zarr/","title":"Napari with OME-Zarr Support","text":"<p>Napari is a fast, interactive, multi-dimensional image viewer for Python, enhanced here with full OME-Zarr support for handling large, multi-dimensional datasets.</p>"},{"location":"tools/napari-ome-zarr/#overview","title":"Overview","text":"<p>This environment provides napari with all necessary dependencies for OME-Zarr support, making it ideal for viewing and analyzing large-scale bio image datasets stored in the OME-Zarr format.</p>"},{"location":"tools/napari-ome-zarr/#environment","title":"Environment","text":"<p>Environment: <code>napari-ome-zarr</code></p>"},{"location":"tools/napari-ome-zarr/#available-tasks","title":"Available Tasks","text":""},{"location":"tools/napari-ome-zarr/#start-napari","title":"Start Napari","text":"<p>Launch the napari viewer with OME-Zarr support:</p> <pre><code>pixi run napari\n</code></pre>"},{"location":"tools/napari-ome-zarr/#plugins-included","title":"Plugins Included","text":"<ul> <li>napari-ome-zarr-navigator: Navigate through OME-Zarr datasets efficiently</li> <li>napari-ome-zarr: Core OME-Zarr support for napari</li> <li>napari-feature-classifier: Classify features in your images</li> <li>napari-feature-visualization: Visualize extracted features</li> <li>napari-animation: Create animations from your multi-dimensional data</li> </ul>"},{"location":"tools/napari-ome-zarr/#features","title":"Features","text":"<ul> <li>Multi-dimensional viewing: Handle 2D, 3D, and higher-dimensional datasets</li> <li>OME-Zarr native support: Seamlessly open and navigate OME-Zarr files</li> <li>Interactive visualization: Real-time exploration of large datasets</li> <li>Plugin ecosystem: Extended functionality through the included plugins</li> <li>Layer-based approach: Organize different data types in separate layers</li> <li>Annotation tools: Built-in tools for manual annotation and measurement</li> </ul>"},{"location":"tools/napari-ome-zarr/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Run <code>pixi run napari</code> to start the napari viewer</li> <li>Open your OME-Zarr datasets and start exploring!</li> </ol>"},{"location":"tools/napari-ome-zarr/#use-cases","title":"Use Cases","text":"<ul> <li>Large dataset visualization: View multi-terabyte OME-Zarr datasets efficiently</li> <li>Multi-channel analysis: Analyze multi-channel fluorescence images</li> <li>Time-series data: Navigate through time-lapse datasets</li> <li>3D visualization: Explore volumetric data with interactive 3D rendering</li> <li>Feature analysis: Use the feature plugins for quantitative analysis</li> </ul>"},{"location":"tools/napari-ome-zarr/#resources","title":"Resources","text":"<ul> <li>Napari documentation</li> <li>OME-Zarr specification</li> <li>Napari tutorials</li> </ul>"},{"location":"tools/plant-seg/","title":"PlantSeg","text":"<p>PlantSeg is a deep learning-based tool specifically designed for cell segmentation in plant tissues, addressing the unique challenges of plant cell structure and morphology.</p>"},{"location":"tools/plant-seg/#overview","title":"Overview","text":"<p>PlantSeg combines deep learning-based boundary prediction with graph partitioning algorithms to achieve accurate cell segmentation in complex 3D plant tissues.</p>"},{"location":"tools/plant-seg/#environment","title":"Environment","text":"<p>Environment: <code>plantseg</code></p>"},{"location":"tools/plant-seg/#available-tasks","title":"Available Tasks","text":""},{"location":"tools/plant-seg/#start-plantseg-gui","title":"Start PlantSeg GUI","text":"<p>Launch the PlantSeg graphical user interface:</p> <pre><code>pixi run plantseg-gui\n</code></pre>"},{"location":"tools/plant-seg/#features","title":"Features","text":"<ul> <li>Deep learning segmentation: State-of-the-art neural networks trained on plant tissues</li> <li>3D cell segmentation: Specialized for volumetric plant imaging data</li> <li>Pre-trained models: Multiple models trained on different plant tissues and organs</li> <li>Graph partitioning: Advanced algorithms for separating touching cells</li> <li>Batch processing: Process multiple datasets efficiently</li> <li>Custom training: Ability to train models on your own plant data</li> <li>Multi-scale analysis: Handle images at different resolutions</li> </ul>"},{"location":"tools/plant-seg/#supported-plant-tissues","title":"Supported Plant Tissues","text":"<ul> <li>Root tissues: Specialized models for root cell segmentation</li> <li>Leaf tissues: Models optimized for leaf cellular structure</li> <li>Shoot apical meristems: Segmentation of meristematic tissues</li> <li>Ovules: Specialized for reproductive tissue analysis</li> <li>General plant tissues: Multi-purpose models for various plant organs</li> </ul>"},{"location":"tools/plant-seg/#workflow-steps","title":"Workflow Steps","text":"<ol> <li>Image preprocessing: Prepare your 3D microscopy data</li> <li>Boundary prediction: Use neural networks to predict cell boundaries</li> <li>Segmentation: Apply graph partitioning to separate individual cells</li> <li>Post-processing: Refine segmentation results</li> <li>Analysis: Extract quantitative measurements from segmented cells</li> </ol>"},{"location":"tools/plant-seg/#getting-started","title":"Getting Started","text":"<ol> <li>Make sure you have pixi installed and this repository cloned</li> <li>Navigate to the repository directory</li> <li>Run <code>pixi run plantseg-gui</code> to start the PlantSeg interface</li> <li>Load your 3D plant imaging data and select appropriate models</li> <li>Run the segmentation pipeline and analyze your results!</li> </ol>"},{"location":"tools/plant-seg/#input-requirements","title":"Input Requirements","text":"<ul> <li>3D image stacks: Confocal or light-sheet microscopy data</li> <li>Supported formats: TIFF, H5, various microscopy formats</li> <li>Cell wall staining: Images with clear cell boundary visualization</li> <li>Resolution: Isotropic or near-isotropic voxel spacing recommended</li> </ul>"},{"location":"tools/plant-seg/#use-cases","title":"Use Cases","text":"<ul> <li>Developmental biology: Track cell divisions and growth in developing organs</li> <li>Cell morphometry: Quantify cell shape, size, and volume</li> <li>Tissue architecture: Analyze 3D tissue organization and structure</li> <li>Comparative studies: Compare cellular organization across different conditions</li> <li>Growth analysis: Study cell expansion and tissue growth patterns</li> </ul>"},{"location":"tools/plant-seg/#resources","title":"Resources","text":"<ul> <li>PlantSeg documentation</li> <li>PlantSeg paper</li> <li>PlantSeg GitHub repository</li> </ul>"}]}